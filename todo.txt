bugs:
  average step times not working
    figure out why sometimes there are no stats being shown

get better at github with H so can have multiple branches going and merge smoothly

integrate Hs github/ youtube stuff into main

how can antarctic prompts happen with one TPU and multiple main programs?
  a ranadom antarctic and is in the request image and resulting txt

figure out what point we are at with OD and get it working with specific items
  predefined objects to zoom into
  beyond:
    it asks what to zoom into while the print is happening
      this could even be done without OD and with a click and drag

some sort of random zoom in to a point thing without even using OD
  this could be done with a click and drag of a box over the image

test:
  test info and prompt videos without antarctic prompts
  antarctic TPU prints generated prompts
  see if additional antarctic prompts are being added

an option to show prompt/s over image
  maybe on top of(with or without a background), maybe above or below image
  maybe show it with put text onto each original X image so that it zooms or moves with the animation
  in order to do prompt overlay on top of interpolated video we need to make the video ourself with
        the interpolation output images

AP Eventually:
  hook up another ai that determines category of antarctic phrases and choose artists/modifiers from list 

OD Eventually:
  gpt3 can be used to combine object detected and current prompt into a new prompt


3D for color:
  if zippy 3d color fx works well,
    get PD set up for 3d and move color fx stuff over
    once this is done, maybe make the first frame become the color pallete for the rest with an option to change it to a later frame

  bug:
    crashes sometimes from memory error
    if it crashes and resumes then i lose all the antarctica prompts

try this without another machine running:
https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/GPT-J-6B/Inference_with_GPT_J_6B.ipynb#scrollTo=9vnZfO1HGSS7

OD and AP:
  if in loop and nothiing happens for long enough then they should stop themselves

AP:
  antarctic prompts special text file doesnt seem to fill up after first one
  in settings text antarctic prompts are not all there, it stopped after about 15 of them, dont know why

Interpolation:
  could be broken up into runs by using a wait system similar to OD and AP

multiply prompts by absolute multiplier
  special consideration must be given for antarctic prompts

Settings/Info files:
  other info text file should keep track of total time in (AP, DO, Pop Diffusion, Interpolation) Interpolation settings, GPU name
  info text file shuld also be in the gist or in a seperate gist

OD
  make an info print of the object that is being zoomed in on (this means send it over from the TPU)
  make a way for more settings to be input, number of frames to reach zoomed object, object to zoom in on if available
    pick either:
      number of frames to reach goal
      speed to head towards goal
      --------for both of these we probably want to pace it so that we reach both at the same time

Settings expirements:
  play with cut_pow less 1.0
  try antarctic with just an init image and either skip all steps on first prompt or get it to make even the first prompt
    so this way it is completely the ai deciding what to do

Live Interaction Stuff:
  a way to add prompts while generation is happening
  a button to cancel current frame/image and delete it

New Animaiton mode:
  make cutn scheduling have new animation mode so it can be different from frame to frame

Misc:
  when i do a series of images in a batch, i should be able to get the seed of each one (when it is on random)
  figure out about finetunning and see if can fine tune on zippys and discord channels to make a helpful DD bot
  a way to load settings from settings file
    this should override the settings in the markdowns

Maybe:
  put lots of optional stuff at the very top instead of having it literred all around
  convert frame skip steps into steps
    this can be a seperate input that goes below it and we can use one or the other. In fact, we can make a special print or something that gives us one if we give the other.
  an estimated completion time would be cool, but probably difficult

Unknown:
  prompt "ramp" overwrite setting system:
    combined with arctic this could be cool
    (maybe this was just an early thought of the current AP system)

Meta:
  figure out a way to test code from in here
    maybe replace google drive with a local folder



show any new setting that is being used there too
  maybe just show all settings here

when we to auto targeted zoom i think we need to have a ration between horizontal and vertical and maybe a speed based on
  distance from center the target is (if we are trying to be able to get to any target location in the same number of frames)

maybe sometimes we pick a target based on how much it has to do with current or next prompt, not sure

maybe sometimes we use the label of the target to help create the next prompt with gpt3

maybe consider moving other things out of main file(not sure, maybe best not to try having more than 2 notebooks running)

find out how many notebooks other people are running at same time in pro+

save average it/s to new text file save list of changing settings to text file
  make sure this is happening

remember to make everything show in settings

learn about skip_augs

look into making models be done with the "new" system

possible to use new init images throughout the print? maybe something involving reverse or something to make it gradually go from one init to another through a prompt? not really thought out yet..

a way to make comparisons of two different changing settings or a control next to each other in one video. Ex: show two slideshows in the same video, in one of them sat_scale is changing, in the other one it is not, and everything else is the same.

a grid comparison of changing settings and their combinations, this could even be a 3d grid or a many dimension grid that is viewed by changing settings(between pre-defined, pre-printed settings) and seeing result in real time


H
make an input variable that is a ccmixter search url like this
http://dig.ccmixter.org/search?searchp=instrumental
get the html of the page, for example ("1 - 40 of 3,714") so the number of songs is 3714
find out how many songs there are for the search url and use that number to make a new url like this
http://dig.ccmixter.org/search?limit=3714&searchp=instrumental
make a list of all song names from this new url
randomly choose a song name
download the song
make a 'credits' string that is the credits for that song

make this downloaded song be the audio for the video
create a description for the youtube video in this format

Created by Pop Diffusion(https://github.com/tjthejuggler/Pop-Diffusion)
a fork of Disco Diffusion(https://github.com/alembics/disco-diffusion)
Settings:
<gist>
Music:
<music credits>