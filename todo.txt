bugs:
  figure out why sometimes there are no stats being shown
testing:
tj: 
  does settings overwrite work for items that are lists?
  we have option to show first prompt in youtube description
    maybe eventually put in the changing aspect of prompt
    maybe make it a function that takes in the prompt and the it maybe just blanks, or something like 1-100 or w/e
  Figure out why difuse has to be seperated and have video settings between itself
  learn how to make a gist branch and use it
  list all features

save video settings to settings.txt and do it in a way that keeps the pre-video settings
put save settings button at bottom of everything

wait:
  if a gist is already made, but then we rerun the the post_difuse stuff again, it makes another gist
    make a gist_url.txt and put the url in there 
    before making a gist check to see if that file exists
      if it does, then check to see if the settings at the gist url are the same as the settings.txt we want to save

if there is no 'unique prompt' video being made, then automatically use standard in frame interpolation

a way to force a specific ccmixter song to be downloaded
  maybe by inputting its url instead of a ccmixter search url

how to make a button?
  make it save current settings to a 'settings templates' folder
how to make a dynamic @param dropdown that gets populated programatically
  with all the settings.txt files in this template folder
  get a settings.txt that is for quick testing with really low settings and use that for testing
  make a settings.txt that has core settings for face animations so that i can just leave that in 
    and not have to change everything every time

Box Zoom:
  to use it we will stop the execution
  then click and drag a box and click submit
    submit sets the next X frames to the apropriate zoom and translate
    then we restart from that point to continue generating

when writing prompts/unique prompts on videos,
  convert from cv2 to PIL,
  add text(so unicode characters can be used),
    (example of characters that cant currently be used: https://studio.youtube.com/video/ZBpqktV35nM/edit)
  and convert back to cv2 (maybe there is no need to convert back if it is saving the images as we need them)
  make params for size and color

when an interpolation is attempted, add its interpolation data to interpolation_observations.txt with status = failed
  make another cell after it that is "update interpolation observations"
    this cell changes the most recent interpolation observation to 'status = success' if all settings are the same as
      what are currently in the program

make a ccmixter 'never again' mp3 list and check for it when getting music, if we get one in the list then loop 
  back and get another one
  -this should be in github AI/Pop_Diffusion/ccmixter_never_again_mp3_list.txt
  -take the url from the music credits (ex: http://dig.ccmixter.org/files/speck/52473) and put it into a list in the txt file
  -when getting a random mp3, check the list and if it is in the list, then get another one

is prompts hooked up to frame multiplier? it should be

make instructions on getting youtube jsons set up

ability to create a whole new main.py by combining a settings.txt with the code, this is a way to actually fill
  in all the settings with a settings.txt file
    -Can probably use this ->>  print(open(__file__).read())
      it prints the entire program, so using that with some sort of replaces in conjunction with a settings.txt
        we should be able to create a filled out new version of the program

how to start with all cells closed by default?

can dynamically morph from x to y using weights in for loops
  example: adorable: 10, creep: -10 ----> adorable: -10, creep: 10

dynamic way to fade through random artists to keep the fade smooth
  example: by 0:a,b,c ; 1:b,c,d ; 2:c,d,e... always just one artists coming and one going

built-in text remover checkbox that automatically adds a -text/words/signature/autograph prompt

at the end of Setup Interpolation cell, compare interpolations to ..AI/Pop_Diffusion/interpolation_observations.txt to see
  if we can tell if the interpolation will fail for sure:
  if we have any failed interpolations with:
    the same gpu
    higher/equal frame dimensions, number of frames, interpolation number
  then we can say pretty much for sure it is going to fail. (although maybe we also have to take into account if another print is currently running)

figure out a smooth way to preview ccmixter mp3s

In settings overwrite there should be an option to use the same antarctic prompts again

3D Color stuff:
  test a long generation with color stuff to see if we can keep color

use the code here to get make and get boxes that can be zoomed into 
  https://hub-binder.mybinder.ovh/user/gereleth-jupyter-bbox-widget-fhggio0w/notebooks/examples/introduction.ipynb

figure out what point we are at with OD and get it working with specific items
  predefined objects to zoom into
  beyond:
    it asks what to zoom into while the print is happening
      this could even be done without OD and with a click and drag

some sort of random zoom in to a point thing without even using OD
  this could be done with a click and drag of a box over the image

test:
  test info and prompt videos without antarctic prompts
  test new antarctic text promp formating 

an option to show prompt/s over image
  maybe on top of(with or without a background), maybe above or below image
  maybe show it with put text onto each original X image so that it zooms or moves with the animation
  in order to do prompt overlay on top of interpolated video we need to make the video ourself with
        the interpolation output images

AP Eventually:
  hook up another ai that determines category of antarctic phrases and choose artists/modifiers from list 

OD Eventually:
  gpt3 can be used to combine object detected and current prompt into a new prompt

3D for color:
  if zippy 3d color fx works well,
    get PD set up for 3d and move color fx stuff over
    once this is done, maybe make the first frame become the color pallete for the rest with an option to change it to a later frame

  bug:
    crashes sometimes from memory error
    if it crashes and resumes then i lose all the antarctica prompts

try this without another machine running:
https://colab.research.google.com/github/NielsRogge/Transformers-Tutorials/blob/master/GPT-J-6B/Inference_with_GPT_J_6B.ipynb#scrollTo=9vnZfO1HGSS7

OD and AP:
  if in loop and nothing happens for long enough then they should stop themselves
  how can antarctic prompts happen with one TPU and multiple main programs?
    a ranadom antarctic and is in the request image and resulting txt

Controlled zoom
  


AP:

Interpolation:
  could be broken up into runs by using a wait system similar to OD and AP

multiply prompts by absolute multiplier
  special consideration must be given for antarctic prompts

Settings/Info files:
  other info text file should keep track of total time in (AP, DO, Pop Diffusion, Interpolation) Interpolation settings, GPU name
  info text file shuld also be in the gist or in a seperate gist

OD
  make an info print of the object that is being zoomed in on (this means send it over from the TPU)
  make a way for more settings to be input, number of frames to reach zoomed object, object to zoom in on if available
    pick either:
      number of frames to reach goal
      speed to head towards goal
      --------for both of these we probably want to pace it so that we reach both at the same time
  maybe sometimes we pick a target based on how much it has to do with current or next prompt, not sure
  maybe sometimes we use the label of the target to help create the next prompt with gpt3

Settings expirements:
  play with cut_pow less 1.0
  try antarctic with just an init image and either skip all steps on first prompt or get it to make even the first prompt
    so this way it is completely the ai deciding what to do

Live Interaction Stuff:
  a way to add prompts while generation is happening
  a button to cancel current frame/image and delete it

New Animaiton mode:
  make cutn scheduling have new animation mode so it can be different from frame to frame
  look into making models be done with the "new" system

Misc:
  when i do a series of images in a batch, i should be able to get the seed of each one (when it is on random)
  figure out about finetunning and see if can fine tune on zippys and discord channels to make a helpful DD bot
  a way to load settings from settings file
    this should override the settings in the markdowns
  possible to use new init images throughout the print? maybe something involving reverse or something to make it gradually go from one init to another through a prompt? not really thought out yet..
  a way to make comparisons of two different changing settings or a control next to each other in one video. Ex: show two slideshows in the same video, in one of them sat_scale is changing, in the other one it is not, and everything else is the same.
  a grid comparison of changing settings and their combinations, this could even be a 3d grid or a many dimension grid that is viewed by changing settings(between pre-defined, pre-printed settings) and seeing result in real time

Maybe:
  put lots of optional stuff at the very top instead of having it literred all around
  convert frame skip steps into steps
    this can be a seperate input that goes below it and we can use one or the other. In fact, we can make a special print or something that gives us one if we give the other.
  an estimated completion time would be cool, but probably difficult

Unknown:
  prompt "ramp" overwrite setting system:
    combined with arctic this could be cool
    (maybe this was just an early thought of the current AP system)

Meta:
  figure out a way to test code from in here
    maybe replace google drive with a local folder

Research:
  find out how many notebooks other people are running at same time in pro+
  learn about skip_augs


